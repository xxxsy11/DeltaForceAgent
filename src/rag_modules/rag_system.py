"""RAG ç³»ç»Ÿå®ç°ä¸è°ƒè¯•å…¥å£ã€‚"""

import time
import logging
from typing import List, Optional
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

from dotenv import load_dotenv

PROJECT_ROOT = Path(__file__).resolve().parents[2]
load_dotenv(PROJECT_ROOT / ".env")

from config import DEFAULT_CONFIG, GraphRAGConfig
from rag_modules.graph_data_preparation import GraphDataPreparationModule
from rag_modules.milvus_index_construction import MilvusIndexConstructionModule
from rag_modules.generation_integration import GenerationIntegrationModule
from rag_modules.hybrid_retrieval import HybridRetrievalModule
from rag_modules.graph_rag_retrieval import GraphRAGRetrieval
from rag_modules.intelligent_query_router import IntelligentQueryRouter


class AdvancedGraphRAGSystem:
    """
    å›¾RAGç³»ç»Ÿ
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. æ™ºèƒ½è·¯ç”±ï¼šè‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„æ£€ç´¢ç­–ç•¥
    2. åŒå¼•æ“æ£€ç´¢ï¼šä¼ ç»Ÿæ··åˆæ£€ç´¢ + å›¾RAGæ£€ç´¢
    3. å›¾ç»“æ„æ¨ç†ï¼šå¤šè·³éå†ã€å­å›¾æå–ã€å…³ç³»æ¨ç†
    4. æŸ¥è¯¢å¤æ‚åº¦åˆ†æï¼šæ·±åº¦ç†è§£ç”¨æˆ·æ„å›¾
    5. è‡ªé€‚åº”å­¦ä¹ ï¼šåŸºäºåé¦ˆä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½
    """
    
    def __init__(self, config: Optional[GraphRAGConfig] = None):
        self.config = config or DEFAULT_CONFIG
        
        # æ ¸å¿ƒæ¨¡å—
        self.data_module = None
        self.index_module = None
        self.generation_module = None
        
        # æ£€ç´¢å¼•æ“
        self.traditional_retrieval = None
        self.graph_rag_retrieval = None
        self.query_router = None
        
        # ç³»ç»ŸçŠ¶æ€
        self.system_ready = False
        
    def initialize_system(self, enable_qa_modules: bool = True):
        """åˆå§‹åŒ–é«˜çº§å›¾RAGç³»ç»Ÿ"""
        logger.info("å¯åŠ¨ä¸‰è§’æ´²è¡ŒåŠ¨å›¾RAGç³»ç»Ÿ...")
        
        try:
            # 1. æ•°æ®å‡†å¤‡æ¨¡å—
            print("åˆå§‹åŒ–æ•°æ®å‡†å¤‡æ¨¡å—...")
            self.data_module = GraphDataPreparationModule(
                uri=self.config.neo4j_uri,
                user=self.config.neo4j_user,
                password=self.config.neo4j_password,
                database=self.config.neo4j_database
            )
            
            # 2. å‘é‡ç´¢å¼•æ¨¡å—
            print("åˆå§‹åŒ–Milvuså‘é‡ç´¢å¼•...")
            self.index_module = MilvusIndexConstructionModule(
                host=self.config.milvus_host,
                port=self.config.milvus_port,
                collection_name=self.config.milvus_collection_name,
                dimension=self.config.milvus_dimension,
                model_name=self.config.embedding_model
            )
            
            if enable_qa_modules:
                self._initialize_qa_modules()
            
            print("âœ… é«˜çº§å›¾RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _initialize_qa_modules(self):
        """åˆå§‹åŒ–é—®ç­”ç›¸å…³æ¨¡å—ï¼ˆLLM + è·¯ç”± + æ£€ç´¢ï¼‰"""
        if self.generation_module and self.traditional_retrieval and self.graph_rag_retrieval and self.query_router:
            return

        print("åˆå§‹åŒ–ç”Ÿæˆæ¨¡å—...")
        self.generation_module = GenerationIntegrationModule(
            model_name=self.config.llm_model,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens
        )

        print("åˆå§‹åŒ–ä¼ ç»Ÿæ··åˆæ£€ç´¢...")
        self.traditional_retrieval = HybridRetrievalModule(
            config=self.config,
            milvus_module=self.index_module,
            data_module=self.data_module,
            llm_client=self.generation_module.llm
        )

        print("åˆå§‹åŒ–å›¾RAGæ£€ç´¢å¼•æ“...")
        self.graph_rag_retrieval = GraphRAGRetrieval(
            config=self.config,
            llm_client=self.generation_module.llm
        )

        print("åˆå§‹åŒ–æ™ºèƒ½æŸ¥è¯¢è·¯ç”±å™¨...")
        self.query_router = IntelligentQueryRouter(
            traditional_retrieval=self.traditional_retrieval,
            graph_rag_retrieval=self.graph_rag_retrieval,
            llm_client=self.generation_module.llm,
            config=self.config
        )
    
    def build_knowledge_base(self, force_rebuild: bool = False, initialize_retrievers: bool = True):
        """ç¦»çº¿æ„å»ºçŸ¥è¯†åº“ï¼ˆå¯é€‰åˆå§‹åŒ–æ£€ç´¢å™¨ï¼‰"""
        print("\nå¼€å§‹ç¦»çº¿æ„å»ºçŸ¥è¯†åº“...")

        try:
            # build æ¨¡å¼é»˜è®¤ä¸è¦†ç›–å·²æœ‰åº“ï¼›rebuild æ¨¡å¼æ‰å¼ºåˆ¶é‡å»º
            if not force_rebuild and self.index_module.has_collection():
                print("âœ… æ£€æµ‹åˆ°å·²å­˜åœ¨çš„Milvusé›†åˆï¼Œbuildæ¨¡å¼è·³è¿‡é‡å»ºã€‚")
                print("å¦‚éœ€å¼ºåˆ¶è¦†ç›–è¯·ä½¿ç”¨ rebuild æ¨¡å¼ã€‚")

                if not self.index_module.load_collection():
                    raise RuntimeError("å·²æœ‰é›†åˆå­˜åœ¨ä½†åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥MilvusçŠ¶æ€åå†è¯•ã€‚")

                print("åŠ è½½å›¾æ•°æ®ä»¥æ›´æ–°ç¦»çº¿ç»Ÿè®¡...")
                self.data_module.load_graph_data()
                self.data_module.build_entity_documents()
                self.data_module.chunk_documents(
                    chunk_size=self.config.chunk_size,
                    chunk_overlap=self.config.chunk_overlap
                )
                self._show_knowledge_base_stats()
                return

            # ä»Neo4jåŠ è½½å›¾æ•°æ®
            print("ä»Neo4jåŠ è½½å›¾æ•°æ®...")
            self.data_module.load_graph_data()
            
            # æ„å»ºå®ä½“æ–‡æ¡£
            print("æ„å»ºå®ä½“æ–‡æ¡£...")
            self.data_module.build_entity_documents()
            
            # è¿›è¡Œæ–‡æ¡£åˆ†å—
            print("è¿›è¡Œæ–‡æ¡£åˆ†å—...")
            chunks = self.data_module.chunk_documents(
                chunk_size=self.config.chunk_size,
                chunk_overlap=self.config.chunk_overlap
            )
            
            # æ„å»ºMilvuså‘é‡ç´¢å¼•
            print("æ„å»ºMilvuså‘é‡ç´¢å¼•...")
            if force_rebuild:
                print("å¼ºåˆ¶é‡å»ºæ¨¡å¼ï¼šå°†è¦†ç›–ç°æœ‰Milvusé›†åˆã€‚")
            if not self.index_module.build_vector_index(
                chunks,
                force_recreate=force_rebuild,
                load_after_build=initialize_retrievers
            ):
                raise Exception("æ„å»ºå‘é‡ç´¢å¼•å¤±è´¥")
            
            # åœ¨çº¿æ¨¡å¼æ‰éœ€è¦åˆå§‹åŒ–æ£€ç´¢å™¨
            if initialize_retrievers:
                self._initialize_retrievers(chunks)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            self._show_knowledge_base_stats()
            
            print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"çŸ¥è¯†åº“æ„å»ºå¤±è´¥: {e}")
            raise

    def load_knowledge_base_for_serving(self):
        """åœ¨çº¿é—®ç­”æ¨¡å¼ï¼šåªåŠ è½½å·²æœ‰ç´¢å¼•ï¼Œä¸è§¦å‘é‡å»º"""
        print("\nåœ¨çº¿æ¨¡å¼ï¼šåŠ è½½å·²æœ‰çŸ¥è¯†åº“...")
        if not self.index_module.has_collection():
            raise RuntimeError(
                f"Milvusé›†åˆ '{self.config.milvus_collection_name}' ä¸å­˜åœ¨ã€‚"
                "è¯·å…ˆåœ¨ config.py è®¾ç½® run_mode='build' å¹¶è¿è¡Œä¸€æ¬¡ç¦»çº¿å»ºåº“ã€‚"
            )

        if not self.index_module.load_collection():
            raise RuntimeError("å·²æœ‰çŸ¥è¯†åº“åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥MilvusçŠ¶æ€ã€‚")

        print("åŠ è½½å›¾æ•°æ®ä»¥æ”¯æŒå›¾æ£€ç´¢...")
        self.data_module.load_graph_data()
        print("æ„å»ºå®ä½“æ–‡æ¡£...")
        self.data_module.build_entity_documents()
        print("è¿›è¡Œæ–‡æ¡£åˆ†å—...")
        chunks = self.data_module.chunk_documents(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap
        )

        self._initialize_retrievers(chunks)
        self._show_knowledge_base_stats()
        print("âœ… åœ¨çº¿çŸ¥è¯†åº“åŠ è½½å®Œæˆï¼")
    
    def _initialize_retrievers(self, chunks: List = None):
        """åˆå§‹åŒ–æ£€ç´¢å™¨"""
        print("åˆå§‹åŒ–æ£€ç´¢å¼•æ“...")
        self._initialize_qa_modules()
        
        # å¦‚æœæ²¡æœ‰chunksï¼Œä»æ•°æ®æ¨¡å—è·å–
        if chunks is None:
            chunks = self.data_module.chunks or []
        
        # åˆå§‹åŒ–ä¼ ç»Ÿæ£€ç´¢å™¨
        self.traditional_retrieval.initialize(chunks)
        
        # åˆå§‹åŒ–å›¾RAGæ£€ç´¢å™¨
        self.graph_rag_retrieval.initialize()
        
        self.system_ready = True
        print("âœ… æ£€ç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆï¼")
    
    def _show_knowledge_base_stats(self):
        """æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nçŸ¥è¯†åº“ç»Ÿè®¡:")
        
        # æ•°æ®ç»Ÿè®¡
        stats = self.data_module.get_statistics()
        print(f"   å®ä½“æ•°é‡: {stats.get('total_nodes', 0)}")
        print(f"   æ–‡æ¡£æ•°é‡: {stats.get('total_documents', 0)}")
        print(f"   æ–‡æœ¬å—æ•°: {stats.get('total_chunks', 0)}")
        
        # Milvusç»Ÿè®¡
        milvus_stats = self.index_module.get_collection_stats()
        print(f"   å‘é‡ç´¢å¼•: {milvus_stats.get('row_count', 0)} æ¡è®°å½•")
        
        # å›¾RAGç»Ÿè®¡
        if self.query_router:
            route_stats = self.query_router.get_route_statistics()
            print(f"   è·¯ç”±ç»Ÿè®¡: æ€»æŸ¥è¯¢ {route_stats.get('total_queries', 0)} æ¬¡")
        else:
            print("   è·¯ç”±ç»Ÿè®¡: é—®ç­”æ¨¡å—æœªåˆå§‹åŒ–ï¼ˆç¦»çº¿å»ºåº“æ¨¡å¼ï¼‰")
        
        if stats.get('label_counts'):
            labels = list(stats['label_counts'].keys())[:10]
            print(f"   ğŸ·ï¸ ä¸»è¦ç±»å‹: {', '.join(labels)}")
    
    def ask_question_with_routing(self, question: str, stream: bool = False, explain_routing: bool = False):
        """
        æ™ºèƒ½é—®ç­”ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³æ£€ç´¢ç­–ç•¥
        """
        if not self.system_ready:
            raise ValueError("ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·å…ˆæ„å»ºçŸ¥è¯†åº“")
            
        print(f"\nâ“ ç”¨æˆ·é—®é¢˜: {question}")
        
        # æ˜¾ç¤ºè·¯ç”±å†³ç­–è§£é‡Šï¼ˆå¯é€‰ï¼‰
        if explain_routing:
            explanation = self.query_router.explain_routing_decision(question)
            print(explanation)
        
        start_time = time.time()
        
        try:
            # 1. æ™ºèƒ½è·¯ç”±æ£€ç´¢
            print("æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢è·¯ç”±...")
            relevant_docs, analysis = self.query_router.route_query(question, self.config.top_k)
            
            # 2. æ˜¾ç¤ºè·¯ç”±ä¿¡æ¯
            strategy_icons = {
                "hybrid_traditional": "ğŸ”",
                "graph_rag": "ğŸ•¸ï¸", 
                "combined": "ğŸ”„"
            }
            strategy_icon = strategy_icons.get(analysis.recommended_strategy.value, "â“")
            print(f"{strategy_icon} ä½¿ç”¨ç­–ç•¥: {analysis.recommended_strategy.value}")
            print(f"ğŸ“Š å¤æ‚åº¦: {analysis.query_complexity:.2f}, å…³ç³»å¯†é›†åº¦: {analysis.relationship_intensity:.2f}")
            
            # 3. æ˜¾ç¤ºæ£€ç´¢ç»“æœä¿¡æ¯
            if relevant_docs:
                doc_info = []
                for doc in relevant_docs:
                    entry_name = doc.metadata.get('recipe_name', doc.metadata.get('entity_name', 'æœªçŸ¥å†…å®¹'))
                    search_type = doc.metadata.get('search_type', doc.metadata.get('route_strategy', 'unknown'))
                    score = doc.metadata.get('final_score', doc.metadata.get('relevance_score', 0))
                    doc_info.append(f"{entry_name}({search_type}, {score:.3f})")
                
                print(f"ğŸ“‹ æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£: {', '.join(doc_info[:3])}")
                if len(doc_info) > 3:
                    print(f"    ç­‰ {len(relevant_docs)} ä¸ªç»“æœ...")
            else:
                # ä¿æŒè¿”å›å€¼ç­¾åä¸€è‡´ï¼šå§‹ç»ˆè¿”å› (result, analysis)
                return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚è¯·å°è¯•å…¶ä»–é—®é¢˜ã€‚", analysis
            
            # 4. ç”Ÿæˆå›ç­”
            print("ğŸ¯ æ™ºèƒ½ç”Ÿæˆå›ç­”...")
            
            if stream:
                try:
                    for chunk_text in self.generation_module.generate_adaptive_answer_stream(question, relevant_docs):
                        print(chunk_text, end="", flush=True)
                    print("\n")
                    result = "æµå¼è¾“å‡ºå®Œæˆ"
                except Exception as stream_error:
                    logger.error(f"æµå¼è¾“å‡ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {stream_error}")
                    print(f"\nâš ï¸ æµå¼è¾“å‡ºä¸­æ–­ï¼Œåˆ‡æ¢åˆ°æ ‡å‡†æ¨¡å¼...")
                    # ä½¿ç”¨éæµå¼ä½œä¸ºåå¤‡
                    result = self.generation_module.generate_adaptive_answer(question, relevant_docs)
            else:
                result = self.generation_module.generate_adaptive_answer(question, relevant_docs)
            
            # 5. æ€§èƒ½ç»Ÿè®¡
            end_time = time.time()
            print(f"\nâ±ï¸ é—®ç­”å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
            
            return result, analysis
            
        except Exception as e:
            logger.error(f"é—®ç­”å¤„ç†å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}", None
    

    

    
    def run_interactive(self):
        """è¿è¡Œäº¤äº’å¼é—®ç­”"""
        if not self.system_ready:
            print("âŒ ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·å…ˆæ„å»ºçŸ¥è¯†åº“")
            return
            
        print("\næ¬¢è¿ä½¿ç”¨ä¸‰è§’æ´²è¡ŒåŠ¨å›¾RAGåŠ©æ‰‹ï¼")
        print("å¯ç”¨åŠŸèƒ½ï¼š")
        print("   - 'stats' : æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡")
        print("   - 'rebuild' : é‡å»ºçŸ¥è¯†åº“")
        print("   - 'quit' : é€€å‡ºç³»ç»Ÿ")
        print("\n" + "="*50)
        
        while True:
            try:
                user_input = input("\næ‚¨çš„é—®é¢˜: ").strip()
                
                if not user_input:
                    continue
                    
                if user_input.lower() == 'quit':
                    break
                elif user_input.lower() == 'stats':
                    self._show_system_stats()
                    continue
                elif user_input.lower() == 'rebuild':
                    self._rebuild_knowledge_base()
                    continue
                
                # æ™®é€šé—®ç­” - ä½¿ç”¨é»˜è®¤è®¾ç½®
                use_stream = True  # é»˜è®¤ä½¿ç”¨æµå¼è¾“å‡º
                explain_routing = False  # é»˜è®¤ä¸æ˜¾ç¤ºè·¯ç”±å†³ç­–

                print("\nå›ç­”:")
                
                result, analysis = self.ask_question_with_routing(
                    user_input, 
                    stream=use_stream, 
                    explain_routing=explain_routing
                )
                
                if not use_stream and result:
                    print(f"{result}\n")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
        
        print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ä¸‰è§’æ´²è¡ŒåŠ¨å›¾RAGåŠ©æ‰‹ï¼")
        self._cleanup()
    
    def _show_system_stats(self):
        """æ˜¾ç¤ºç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        print("\nç³»ç»Ÿè¿è¡Œç»Ÿè®¡")
        print("=" * 40)

        if not self.query_router:
            print("é—®ç­”æ¨¡å—æœªåˆå§‹åŒ–ï¼Œå½“å‰æ¨¡å¼ä¸æä¾›è¿è¡Œç»Ÿè®¡ã€‚")
            self._show_knowledge_base_stats()
            return
        
        # è·¯ç”±ç»Ÿè®¡
        route_stats = self.query_router.get_route_statistics()
        total_queries = route_stats.get('total_queries', 0)
        
        if total_queries > 0:
            print(f"æ€»æŸ¥è¯¢æ¬¡æ•°: {total_queries}")
            print(f"ä¼ ç»Ÿæ£€ç´¢: {route_stats.get('traditional_count', 0)} ({route_stats.get('traditional_ratio', 0):.1%})")
            print(f"å›¾RAGæ£€ç´¢: {route_stats.get('graph_rag_count', 0)} ({route_stats.get('graph_rag_ratio', 0):.1%})")
            print(f"ç»„åˆç­–ç•¥: {route_stats.get('combined_count', 0)} ({route_stats.get('combined_ratio', 0):.1%})")
        else:
            print("æš‚æ— æŸ¥è¯¢è®°å½•")
        
        # çŸ¥è¯†åº“ç»Ÿè®¡
        self._show_knowledge_base_stats()
    
    def _rebuild_knowledge_base(self):
        """é‡å»ºçŸ¥è¯†åº“"""
        print("\nå‡†å¤‡é‡å»ºçŸ¥è¯†åº“...")
        
        # ç¡®è®¤æ“ä½œ
        confirm = input("âš ï¸  è¿™å°†åˆ é™¤ç°æœ‰çš„å‘é‡æ•°æ®å¹¶é‡æ–°æ„å»ºï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
        if confirm != 'y':
            print("âŒ é‡å»ºæ“ä½œå·²å–æ¶ˆ")
            return
        
        try:
            print("åˆ é™¤ç°æœ‰çš„Milvusé›†åˆ...")
            if self.index_module.delete_collection():
                print("âœ… ç°æœ‰é›†åˆå·²åˆ é™¤")
            else:
                print("åˆ é™¤é›†åˆæ—¶å‡ºç°é—®é¢˜ï¼Œç»§ç»­é‡å»º...")
            
            # é‡æ–°æ„å»ºçŸ¥è¯†åº“
            print("å¼€å§‹é‡å»ºçŸ¥è¯†åº“...")
            self.build_knowledge_base(force_rebuild=True, initialize_retrievers=True)
            
            print("âœ… çŸ¥è¯†åº“é‡å»ºå®Œæˆï¼")
            
        except Exception as e:
            logger.error(f"é‡å»ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            print(f"âŒ é‡å»ºå¤±è´¥: {e}")
            print("å»ºè®®ï¼šè¯·æ£€æŸ¥MilvusæœåŠ¡çŠ¶æ€åé‡è¯•")
    
    def _cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.data_module:
            self.data_module.close()
        if self.traditional_retrieval:
            self.traditional_retrieval.close()
        if self.graph_rag_retrieval:
            self.graph_rag_retrieval.close()
        if self.index_module:
            self.index_module.close()

def run_rag_mode(mode: str | None = None):
    """
    RAG è°ƒè¯•å…¥å£ï¼Œä»…ç”¨äº RAG å­ç³»ç»Ÿï¼š
    - build
    - rebuild
    - serve
    """
    rag_system = AdvancedGraphRAGSystem()
    selected_mode = mode or rag_system.config.run_mode
    if selected_mode == "agent":
        selected_mode = "serve"

    print(f"RAG è°ƒè¯•æ¨¡å¼: {selected_mode}")

    if selected_mode == "build":
        rag_system.initialize_system(enable_qa_modules=False)
        rag_system.build_knowledge_base(force_rebuild=False, initialize_retrievers=False)
        print("âœ… ç¦»çº¿å»ºåº“å®Œæˆã€‚")
        rag_system._cleanup()
        return

    if selected_mode == "rebuild":
        rag_system.initialize_system(enable_qa_modules=False)
        print("åˆ é™¤ç°æœ‰çš„Milvusé›†åˆ...")
        if rag_system.index_module.delete_collection():
            print("âœ… ç°æœ‰é›†åˆå·²åˆ é™¤")
        else:
            print("åˆ é™¤é›†åˆæ—¶å‡ºç°é—®é¢˜ï¼Œç»§ç»­é‡å»º...")
        rag_system.build_knowledge_base(force_rebuild=True, initialize_retrievers=False)
        print("âœ… ç¦»çº¿é‡å»ºå®Œæˆã€‚")
        rag_system._cleanup()
        return

    rag_system.initialize_system(enable_qa_modules=True)
    rag_system.load_knowledge_base_for_serving()
    rag_system.run_interactive()


if __name__ == "__main__":
    try:
        run_rag_mode()
    except Exception as e:
        logger.error(f"RAG è°ƒè¯•è¿è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        print(f"\nâŒ ç³»ç»Ÿé”™è¯¯: {e}")
